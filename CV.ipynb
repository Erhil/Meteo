{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# matplotlib plotting\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.animation as animation\n",
    "# images\n",
    "import cv2 # OpenCV\n",
    "from PIL import Image\n",
    "# outlier detection\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "# clustering\n",
    "from sklearn.cluster import *\n",
    "# numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define initial variables\n",
    "\n",
    "* **title**: video file name\n",
    "* **feature_params**: params for feature extraction\n",
    "* **lk_params**: params for Lucasâ€“Kanade method\n",
    "* **mem**: memory size, how long features will be tracked\n",
    "* ***view params***:\n",
    "     * **distr**: view type. If 0, view vectors and position; if 1, view only length  and direction\n",
    "     * **dits**: if 0, view vectors as lines, if 1, view vectors as arrows\n",
    "     * **cluster**: if 0, disable clustering, if 1, enable clustering\n",
    "     * **outlier**: if 0, process all data, if 1, exclude outliers\n",
    "     * **bg**: only for distr=0, if 1, show image on background, if 0, show only vectors\n",
    "* ***outlier params***\n",
    "     * ***Isolation Forest***\n",
    "         * **n_trees**: number of trees in isolation forest\n",
    "         * **cont**: contamination of isolation forest\n",
    "     * ***One Class SVM***\n",
    "         * **nu**: nu of One Class SVM\n",
    "         * **gama**: gamma of One Class SVM\n",
    "         * **kearnel**: SVM kernal; best is \"rbf\"\n",
    "* ***Clustering param***\n",
    "    * **eps**: epsilon param of DBSCAN\n",
    "    * **l_lize**: number of examples in single leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#params\n",
    "title = \"flow300.mp4\"\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 10000,\n",
    "                       qualityLevel = 0.01,\n",
    "                       minDistance = 8,\n",
    "                       blockSize = 8 )\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (30,30),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 100, 0.03))\n",
    "#memory length\n",
    "mem = 10\n",
    "#view params\n",
    "distr = 0\n",
    "dots = 1\n",
    "cluster = 1\n",
    "outlier = 1\n",
    "bg = 1\n",
    "\n",
    "\n",
    "#outlier params\n",
    "n_trees = 50\n",
    "cont = 0.5\n",
    "nu = 0.5\n",
    "gama = 0.5\n",
    "kernel = \"rbf\"\n",
    "\n",
    "# clustering param\n",
    "eps = 70\n",
    "l_size = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#color settings\n",
    "cmap_hm = [[255-i,0,i] for i in range(0,512,5)]\n",
    "cmap_cl = [[255,0,0],\n",
    "           [0,255,0],\n",
    "           [0,0,255],\n",
    "           [255,255,0],\n",
    "           [255,0,255],\n",
    "           [0,255,255],\n",
    "           [0,128,255],\n",
    "           [0,255,128],\n",
    "           [255,0,128],\n",
    "           [128,0,255],\n",
    "           [128,0,128],\n",
    "           [0,128,128],\n",
    "           [128,128,0],\n",
    "           [255,128,0],\n",
    "           [128,255,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define some support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#additional functions\n",
    "leng = lambda x, y: np.sqrt((x[0]-y[0])*(x[0]-y[0])+(x[1]-y[1])*(x[1]-y[1]))\n",
    "col = lambda x: cmap_hm[int(x)]\n",
    "col_cls = lambda x: cmap_cl[x+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Build\\OpenCV\\opencv-3.2.0\\modules\\imgproc\\src\\color.cpp:9748: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(title)\n",
    "# outlier detection method\n",
    "if outlier:\n",
    "    #outl = IsolationForest(n_estimators= n_trees, contamination= cont, n_jobs=4)\n",
    "    outl = OneClassSVM(kernel=kernel, nu=nu, gamma=gama)\n",
    "# clustering\n",
    "if cluster:\n",
    "    cls = DBSCAN(eps=eps, leaf_size=l_size, n_jobs = -1, algorithm='kd_tree')\n",
    "    #cls = MeanShift(n_jobs=4)\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "# Create a mask image for drawing purposes\n",
    "masks = [np.zeros_like(old_frame) for i in range(mem)] \n",
    "vecs = [np.zeros((1,4)) for i in range(mem)]\n",
    "try:\n",
    "    while(1):\n",
    "        ret,frame = cap.read()\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # calculate optical flow\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "        # Select good points\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "\n",
    "        # draw the tracks\n",
    "        masks.append(np.zeros_like(old_frame))\n",
    "        vecs.append(np.zeros((1,4)))\n",
    "        for i in range(len(vecs)):\n",
    "            vecs[i] = np.vstack([vecs[i], np.hstack([good_new-good_old, good_old])]) \n",
    "                                # + frame_gray[good_new[:,1].astype(int), good_new[:,0].astype(int)]\n",
    "        vec = vecs.pop(0)\n",
    "        if outlier:\n",
    "            outl.fit(vec)\n",
    "            pred = outl.predict(vec)\n",
    "        else:\n",
    "            pred = -1*np.ones(vec.shape[0])\n",
    "        if cluster:\n",
    "            clus = cls.fit_predict(vec) # FOR DBSCAN ONLY!!!\n",
    "            #cls.fit(vec)\n",
    "            #clus = cls.predict(np.hstack([good_new-good_old, good_old]))\n",
    "        if distr:\n",
    "            for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "                a,b = new.ravel()\n",
    "                c,d = old.ravel()\n",
    "                ln=leng((a,b), (c,d))\n",
    "                if 4<ln<50 and (not outlier or pred[i] == -1):\n",
    "                    if cluster:\n",
    "                        co = col_cls(clus[i])\n",
    "                    else:\n",
    "                        co = col(ln)\n",
    "                    for j in masks:\n",
    "                        if dots:\n",
    "                            j = cv2.circle(j,(int(400+(a-c)*5), int(300+(b-d)*5)),2,co,-1)\n",
    "                        else:\n",
    "                            j = cv2.line(j, (400,300),(int(400+(a-c)*5), int(300+(b-d)*5)),co, 1)\n",
    "        else:\n",
    "            for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "                a,b = new.ravel()\n",
    "                c,d = old.ravel()\n",
    "                ln=leng((a,b), (c,d))\n",
    "                if 4<ln<50 and (not outlier or pred[i] == -1):\n",
    "                    if cluster:\n",
    "                        co = col_cls(clus[i])\n",
    "                    else:\n",
    "                        co = col(ln)\n",
    "                    for j in masks:\n",
    "                        j = cv2.line(j, (a,b),(c,d), co, 1)\n",
    "                        if dots:\n",
    "                            j = cv2.circle(j,(a,b),1,co,-1)\n",
    "        mask = masks.pop(0)\n",
    "        if not distr and bg:\n",
    "            img = cv2.add(255-frame,mask)\n",
    "        else:\n",
    "            img = mask\n",
    "\n",
    "        cv2.imshow('frame',img)\n",
    "        k = cv2.waitKey(100) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "        # Now update the previous frame and previous points\n",
    "        old_gray = frame_gray.copy()\n",
    "        p0 = np.vstack([good_new.reshape(-1,1,2),cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)])[-100:,:,:]\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
